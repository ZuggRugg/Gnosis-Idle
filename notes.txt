* Structure of the Project | Modularize
//TODO: Break up the compiler.cpp file into Lexer/Parser/Interpreter
//TODO: Make Main file where everything is executed
  
Lexer has the Tokens and the functions related to Get_next_token()
Parser has stuff related to eat(), term(), factor(), and expr()
Interpreter has new functions around AST, interacts with parser.



* how term and operator precedence works
- term deals with multiplying and dividing
- new method called factor which returns current_token.value and then eats token
- the expr function now again deals with plus and minus operators
     expr   : term ((PLUS | MINUS) term)*
     term   : factor ((MUL | DIV) factor)*
     factor : INTEGER      

     expr -> term -> factor
     where expr immediatly hands it off to term which checks the higher precedence first
     then hands it back to expr to check the lower precedence operators.
     the factor() method is used to check for Integer/Numbers then eat the current_token    



* get_tokens
void get_tokens(std::string rec, std::vector<token>& t_answer) {
  for (int i = 0; i < rec.length(); i++) {
    
    if (rec[i] == '+') { //check if its + operator
      t_answer.push_back({PLUS, 999});
    }

    if(isdigit(rec[i])) { 
      int number = rec[i] - '0';  // Convert char digit to int
      t_answer.push_back({NUMBER, number});
    }

    if(rec[i] == ' ') {
      t_answer.push_back({WHITESPACE, 999});
    }

    if(i == rec.length()-1) { t_answer.push_back({EOF_, 999}); } // add end of file token
  }

  //read tokens
  for(int i = 0; i < t_answer.size(); i++) {
    std::cout << getTokenName(t_answer[i].type) << " - " << t_answer[i].value << "\n"; 
  }
}


